Score = c(
# Placebo
0.90,0.82,1.00,1.12,0.74,0.93,1.02,1.21,0.84,0.91,1.08,0.86,
# Low
0.10,0.00,-0.10,0.20,0.05,-0.05,0.15,0.00,-0.10,0.12,0.06,0.01,
# Med
-0.30,-0.42,-0.22,-0.50,-0.35,-0.27,-0.31,-0.46,-0.38,-0.20,-0.36,-0.29,
# High
0.40,0.32,0.50,0.36,0.25,0.46,0.41,0.52,0.35,0.30,0.44,0.39
)
)
a <- run_oneway(data = drug,
dv = "Score",
group = "Dose",
parametric = T)
a
habanero <- c(105.5,100.7,96.5,107.3,100.6,96.3,99.5,
98.9,107.4,103.8,109.3,107.7,103.2,104.5,
95.4,103.3,107.5,101.8,106.1,102.6)
jalapeño <- c(109.1,111.7,118.6,111.1,100.5,118.7,117.5,
102.1,94.9,104.0,109.2,101.1,113.0,111.3,97.6,
109.2,93.4,103.4,90.3,109.2)
peppers <- cbind(jalapeño, habanero) |> as.data.frame()
t.test(jalapeño, habanero, alternative = "greater")
shapiro.test(habanero)
shapiro.test(jalapeño)
iris |>
select(species != "setosa") |>
group_by(species) |>
dplyr::summarise(p.value = shapiro.test(Petal.Width)$p.value)
iris |>
filter(species != "setosa") |>
group_by(species) |>
dplyr::summarise(p.value = shapiro.test(Petal.Width)$p.value)
library(tidyverse)
iris |>
filter(species != "setosa") |>
group_by(species) |>
dplyr::summarise(p.value = shapiro.test(Petal.Width)$p.value)
iris |>
filter(Species != "setosa") |>
group_by(Species) |>
dplyr::summarise(p.value = shapiro.test(Petal.Width)$p.value)
iris |>
filter(Species != "setosa") |>
group_by(Species) |>
dplyr::summarise(p.value = shapiro.test(sqrt(Petal.Width))$p.value)
iris |>
filter(Species != "setosa") |>
group_by(Species) |>
dplyr::summarise(p.value = shapiro.test((Petal.Width)^2)$p.value)
iris |>
filter(Species != "setosa") |>
group_by(Species) |>
dplyr::summarise(p.value = shapiro.test(log1p(Petal.Width))$p.value)
mean(flint_mdeq$lead>15)
owner_name <- c(2.0,1.3,3.4,2.6,2.6,0.8,2.6,1.9,0.3,0.9)
owner_sight <- c(2.8,4.3,3.0,3.9,2.7,3.4,3.3,3.7,2.8,3.4)
dog_data <- cbind(owner_name, owner_sight) |>
as.data.frame()
t.test(owner_name, owner_sight, paired = T, alternative = "less")
rufula <- c(68.6,71.7,69.9,74.9,70.2,64.9,70.8,74.2,67.1,70.8,75.0,70.7)
melanocrissus <- c(73.8,82.1,70.5,75.4,73.4,67.4,71.5,75.9,68.6,72.4,67.5,73.8)
swallows <- cbind(rufula, melanocrissus) |>
as.data.frame()
t.test(rufula, melanocrissus, alternative = "two.sided")
habanero <- c(105.5,100.7,96.5,107.3,100.6,96.3,99.5,
98.9,107.4,103.8,109.3,107.7,103.2,104.5,
95.4,103.3,107.5,101.8,106.1,102.6)
jalapeño <- c(109.1,111.7,118.6,111.1,100.5,118.7,117.5,
102.1,94.9,104.0,109.2,101.1,113.0,111.3,97.6,
109.2,93.4,103.4,90.3,109.2)
peppers <- cbind(jalapeño, habanero) |> as.data.frame()
t.test(jalapeño, habanero, alternative = "greater")
versicolor <- iris |>
dplyr::filter(Species == "versicolor")
virginica <- iris |>
dplyr::filter(Species == "virginica")
# DATA CANNOT BE NORMALIZED
wilcox.test(versicolor$Petal.Width, virginica$Petal.Width, alternative = "two.sided")
media_A <- c(16,14,12,16,16,16,13,16,15,15,
15,15,15,15,17,15,16,15,15,13,
15,15,15,14,14,14,15,15,15,15,
14,14,14,16,17,15,13,14,16,16)
media_B <- c(12,12,12,12,11,11,11,13,12,11,
11,11,10,11,13,10,10,11,17,15,
13,14,18,16,19,15,16,16,15,19,
16,17,16,20,16,15,19,16,18,18)
# data cannot be normalized!
wilcox.test(media_A, media_B, alternative = "greater")
library(tidytuesdayR)
tuesdata <- tidytuesdayR::tt_load('2025-11-04')
flint_mdeq <- tuesdata$flint_mdeq |>
dplyr::select(-notes) |>
na.omit() |>
dplyr::select(-lead2)
group1 <- flint_mdeq[1:20,]
group2 <- flint_mdeq[21:40,]
# need to log1p transform
t.test(log1p(group1$lead), log1p(group2$lead))
mean(flint_mdeq$lead>15)
flint_mdeq$lead |> shapiro.test()
flint_mdeq$lead^2 |> shapiro.test()
flint_mdeq$lead |> sqrt() |> shapiro.test()
flint_mdeq$lead |> log1p() |> shapiro.test()
flint_mdeq$lead |> log10() |> shapiro.test()
flint_mdeq$lead |> log1p() |> shapiro.test()
wilcox.test(flint_mdeq$lead, mu = 15, alternative = "g")
wilcox.test(flint_mdeq$lead, mu = 15, alternative = "l")
library(tidyverse)
waterbirds <- read_csv("harlan_waterbirds.csv")
waterbirds_expanded <- waterbirds |>
na.omit() |>
pivot_longer(!`COMMON NAME`,
names_to = "Year",
values_to = "Count")
waterbirds_expanded$Year <- as.numeric(waterbirds_expanded$Year)
species <- unique(waterbirds_expanded$`COMMON NAME`)
species
study_taxa <- waterbirds_expanded |>
filter(`COMMON NAME`=="Common Merganser"&`COMMON NAME`=="Green-winged Teal")
study_taxa
study_taxa <- waterbirds_expanded |>
filter(`COMMON NAME`=="Common Merganser"|`COMMON NAME`=="Green-winged Teal")
study_taxa
study_taxa <- waterbirds_expanded |>
filter(`COMMON NAME`=="Common Merganser"|`COMMON NAME`=="Green-winged Teal") |>
mutate(log_count = log1p(Count))
study_taxa
ggplot(study_taxa, aes(x = Year, y = log_count, shape = `COMMON NAME`)) +
geom_line() +
theme_minimal()
ggplot(study_taxa, aes(x = Year, y = log_count, shape = `COMMON NAME`)) +
geom_point() +
geom_line() +
theme_minimal()
ggplot(study_taxa, aes(x = Year, y = log_count, shape = `COMMON NAME`)) +
geom_point(size = 4) +
geom_line() +
theme_minimal()
ggplot(study_taxa, aes(x = Year, y = log_count, shape = `COMMON NAME`)) +
geom_point(size = 4) +
geom_line() +
geom_vline(mapping = 2019)
ggplot(study_taxa, aes(x = Year, y = log_count, shape = `COMMON NAME`)) +
geom_point(size = 4) +
geom_line() +
geom_vline(xintercept = 2019) +
theme_minimal()
ggplot(study_taxa, aes(x = Year, y = log_count, shape = `COMMON NAME`)) +
geom_point(size = 4) +
geom_line() +
geom_vline(xintercept = 2019, linetype = "dashed", size = 2) +
theme_minimal()
ggplot(study_taxa, aes(x = Year, y = Count, shape = `COMMON NAME`)) +
geom_point(size = 4) +
geom_line() +
geom_vline(xintercept = 2019, linetype = "dashed", size = 2) +
theme_minimal()
ggplot(study_taxa, aes(x = Year, y = log_count, shape = `COMMON NAME`)) +
geom_point(size = 4) +
geom_line() +
geom_vline(xintercept = 2019, linetype = "dashed", size = 2) +
theme_minimal()
summary(iris)
iris_data_only <- iris |>
select(-Species)
iris_pca <- princomp(iris_data_only, scores = T)
summary(iris_pca)
iris_expanded <- cbind(iris, iris_pca$scores)
iris_pca <- princomp(iris_data_only)
summary(iris_pca)
iris_expanded <- cbind(iris, iris_pca$scores)
iris_expanded <- cbind(iris, iris_pca$scores)
ggplot(iris_expanded, aes(x = Comp.1, y = Comp.2, colour = Species, shape = Species)) +
geom_point() + theme_classic()
ggplot(iris_expanded, aes(x = Comp.1, y = Comp.2, colour = Species, shape = Species)) +
geom_point(size = 2) + theme_classic()
ggplot(iris_expanded, aes(x = Comp.1, y = Comp.2, colour = Species, shape = Species)) +
geom_point(size = 4) + theme_classic()
ggplot(iris_expanded, aes(x = Comp.1, y = Comp.2, colour = Species, shape = Species)) +
geom_point(size = 3) + theme_classic()
ggplot(iris_expanded, aes(x = Comp.1,
y = Comp.2,
colour = Species,
shape = Species)) +
geom_point(size = 3) +
theme_classic() +
scale_color_viridis_b()
ggplot(iris_expanded, aes(x = Comp.1,
y = Comp.2,
colour = Species,
shape = Species)) +
geom_point(size = 3) +
theme_classic() +
scale_color_viridis_d()
ggplot(iris_expanded, aes(x = Comp.1,
y = Comp.2,
colour = Species,
shape = Species)) +
geom_point(size = 3) +
theme_minimal() +
# make colorblind friendly
scale_color_viridis_d()
ggplot(iris_expanded, aes(x = Comp.1,
y = Comp.2,
colour = Species,
shape = Species)) +
geom_point(size = 3) +
theme_minimal() +
ylab("PCA 2") +
xlab("PCA 1") +
# make colorblind friendly
scale_color_viridis_d()
ggplot(iris_expanded, aes(x = Comp.1,
y = Comp.2,
colour = Species,
shape = Species)) +
geom_point(size = 3) +
theme_minimal() +
ylab("PC 2") +
xlab("PC 1") +
# make colorblind friendly
scale_color_viridis_d()
read_csv("https://escholarship.org/content/qt03b9b2rw/supp/TableS2_Differences-between-lists.ods")
library(UNKstats)
summary(iris)
data(afromontane)
summary(afromontane)
y <- 1:10
y
mean(y > 6)
y <- 1:100000000
mean(y > 6)
y > 6
versicolor <- iris |>
dplyr::filter(Species == "versicolor")
virginica <- iris |>
dplyr::filter(Species == "virginica")
wilcox.test(versicolor$Petal.Width, virginica$Petal.Width, alternative = "two.sided")
y <- 1:100
> y
y > 15
sum(y > 15)
mean(y > 15)
# Install roxygen2 from CRAN
install.packages("roxygen2")
install.packages("roxygen2")
pak::pak("r-lib/roxygen2")
update.packages()
getwd()
setwd("~/Documents/GitHub/UNKstats/")
getwd()
library(roxygen2)
roxygenize()
remotes::install_github("CalebRother/UNKstats")
library(UNKstats)
se
?se
roxygenize()
remotes::install_github("CalebRother/UNKstats")
remotes::install_github("CalebRother/UNKstats")
library(UNKstats)
zscore
# download data
starbucks <- read_csv("https://raw.githubusercontent.com/jacobccooper/biol105_unk/main/datasets/starbucks.csv")
# enables data management tools
library(tidyverse)
library(UNKstats)
# download data
starbucks <- read_csv("https://raw.githubusercontent.com/jacobccooper/biol105_unk/main/datasets/starbucks.csv")
head(starbucks)
# get vector of frappuccino number
fraps <- starbucks$Frap_Num
# get mean of vector
mean(fraps)
mean(fraps) |>
round(0)
# OR
round(mean(fraps),0)
# sum values
# divide by n, length of vector
# round to 0 places
round(sum(fraps)/length(fraps),0)
max(fraps) - min(fraps)
range(fraps)
# use default
median(fraps)
length(fraps)
# order gets the order
order(fraps)
# [] tells R which elements to put where
frap_order <- fraps[order(fraps)]
frap_order
# always use parentheses
# make sure the math maths right!
(length(frap_order)+1)/2
frap_order[5]
# remove first element
even_fraps <- fraps[-1]
even_fraps_order <- even_fraps[order(even_fraps)]
even_fraps_order
#### Even number of values
Given that we are trying to find the "middle" number, this is more complicated when using a vector that has an even number of values. Let's calculate this by hand:
#### Even number of values
Given that we are trying to find the "middle" number, this is more complicated when using a vector that has an even number of values. Let's calculate this by hand:
#### Even number of values
Given that we are trying to find the "middle" number, this is more complicated when using a vector that has an even number of values. Let's calculate this by hand:
# enables data management tools
library(tidyverse)
library(UNKstats)
# download data
starbucks <- read_csv("https://raw.githubusercontent.com/jacobccooper/biol105_unk/main/datasets/starbucks.csv")
head(starbucks)
# get vector of frappuccino number
fraps <- starbucks$Frap_Num
# get mean of vector
mean(fraps)
mean(fraps) |>
round(0)
# OR
round(mean(fraps),0)
# sum values
# divide by n, length of vector
# round to 0 places
round(sum(fraps)/length(fraps),0)
max(fraps) - min(fraps)
range(fraps)
# use default
median(fraps)
length(fraps)
# order gets the order
order(fraps)
# [] tells R which elements to put where
frap_order <- fraps[order(fraps)]
frap_order
# always use parentheses
# make sure the math maths right!
(length(frap_order)+1)/2
frap_order[5]
# remove first element
even_fraps <- fraps[-1]
even_fraps_order <- even_fraps[order(even_fraps)]
even_fraps_order
median(even_fraps)
n <- length(even_fraps_order)
# get n/2 position from vector
m1 <- even_fraps_order[n/2]
# get n/2+1 position
m2 <- even_fraps_order[(n/2)+1]
# add these values, divide by two for "midpoint"
med <- (m1+m2)/2
med
#### Even number of values
Given that we are trying to find the "middle" number, this is more complicated when using a vector that has an even number of values. Let's calculate this by hand:
n <- length(even_fraps_order)
# get n/2 position from vector
m1 <- even_fraps_order[n/2]
# get n/2+1 position
m2 <- even_fraps_order[(n/2)+1]
# add these values, divide by two for "midpoint"
med <- (m1+m2)/2
med
cc
### Other quartiles and quantiles {.tight-top}
We also use the 25th percentile (25%, 0.25) and the 75th percentile (75%, 0.75) to understand data distributions. These are calculated similar to the above, but the bottom quartile is only $\frac{1}{4}$ of the way between values and the 75th quartile is $\frac{3}{4}$ of the way between values. We can use the *R* function `quantile` to calculate these. **Before implementing, please read this whole section - *R* has nine different methods for calculating the quantiles!**
median(even_fraps)
n <- length(even_fraps_order)
# get n/2 position from vector
m1 <- even_fraps_order[n/2]
# get n/2+1 position
m2 <- even_fraps_order[(n/2)+1]
# add these values, divide by two for "midpoint"
med <- (m1+m2)/2
med
quantile(frap_order)
# 75th percentile
n <- length(even_fraps_order)
# get position
p <- 0.75*(n+1)
# get lower value
# round down
m1 <- even_fraps_order[trunc(p)]
# get upper value
# round up
m2 <- even_fraps_order[ceiling(p)]
# position between
# fractional portion of rank
frac <- p-trunc(p)
# calculate the offset from lowest value
val <- (m2 - m1)*frac
# get value
m1 + val
quantile(even_fraps_order, type = 6)
# unique counts
u <- unique(fraps)
u
# which elements match
match(fraps,u)
# count them
tab <- match(fraps,u) |>
tabulate()
tab
u[tab == max(tab)]
2 == 2
2 == 3
sum(2 == 2)
sum(2 == 3)
find_mode(fraps)
x <- fraps
# get unique values from vector
u <- unique(x)
u
# count number of occurrences for each value
tab <- tabulate(match(x, u))
tab
u[tab == max(tab)]
max(tab)
# return the value with the highest count
u[tab == max(tab)]
u
tab
frap
x
max(tab)
roxygenise()
remotes::install_github("CalebRother/UNKstats")
library(UNKstats)
find_mode(fraps)
se(frap_order)
cv(frap_order) |>
round(2)
(CoefVar(frap_order)*100) |>
round(2)
library(DescTools)
(CoefVar(frap_order)*100) |>
round(2)
# don't forget to install, if needed!
library(DescTools)
Outlier(frap_order)
tuesdata <- tidytuesdayR::tt_load(2025, week = 13)
pokemon_df <- tuesdata$pokemon_df
pokemon_df
pokemon_df |> mutate(attack_defense = attack/defense) |>
pokemon_df
pokemon_df <- tuesdata$pokemon_df
pokemon_df |> mutate(attack_defense = attack/defense) |>
pokemon_df
pokemon_df
pokemon_df
pokemon_df |> mutate(attack_defense = attack/defense) |>
pokemon_df
library(tidyverse)
pokemon_df |>
mutate(attack_defense = attack/defense) |>
pokemon_df
pokemon_df |>
dplyr::mutate(attack_defense = attack/defense) |>
pokemon_df
?mutate
pokemon_df |>
dplyr::mutate(attack_defense = attack/defense) ->
pokemon_df
pokemon_df
aov(data = pokemon_df, attack_defense ~ type_1 + egg_group_1)
poke_aov <- aov(data = pokemon_df, attack_defense ~ type_1 + egg_group_1)
summary(poke_aov)
install.packages("remotes")
remotes::install_github("CalebRother/UNKstats")
library(UNKstats)
iris
run_oneway(data = iris,
dv = "Sepal.Length",
group = "Species")
run_oneway(data = iris,
dv = "Sepal.Length",
group = "Species")
run_oneway(data = iris,
dv = "Sepal.Length",
group = "Species",
parametric = T)
iris
run_oneway(data = iris,
dv = "Sepal.Width",
group = "Species",
parametric = T)
run_oneway(data = iris,
dv = "Petal.Length",
group = "Species",
parametric = T)
iris
run_oneway(data = iris,
dv = "Petal.Width",
group = "Species",
parametric = T)
penguin
mtcars
run_oneway(data = mtcars,
dv = "mpg",
group = "cyl",
parametric = T)
mtcars
run_oneway(data = mtcars,
dv = "mpg",
group = "vs",
parametric = T)
zscore
cv
se
?se
data("afromontane")
afromontane
